<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="序特征工程之后，我们基本了解了数据集的概貌，通过缺失值处理、异常值处理、归一化、独热编码、特征构造等一系列方法对数据进行了预处理，并根据不同模型的数据要求对数据进行了一定的转化，从而进行下一步模型的学习过程。以下就是对数据进行处理后，训练模型的过程代码。其实可以先使用随机森林等方法先做一步特征筛选的工作，我这里没有做特征的筛选，而且先复现了数据准备，模型构造和调参的过程。若是模型初步表现不错且较稳">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习训练_金融风控_Task4_建模调参">
<meta property="og:url" content="http://example.com/2023/04/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83_%E9%87%91%E8%9E%8D%E9%A3%8E%E6%8E%A7_Task4_%E5%BB%BA%E6%A8%A1%E8%B0%83%E5%8F%82/index.html">
<meta property="og:site_name" content="大宝的树屋">
<meta property="og:description" content="序特征工程之后，我们基本了解了数据集的概貌，通过缺失值处理、异常值处理、归一化、独热编码、特征构造等一系列方法对数据进行了预处理，并根据不同模型的数据要求对数据进行了一定的转化，从而进行下一步模型的学习过程。以下就是对数据进行处理后，训练模型的过程代码。其实可以先使用随机森林等方法先做一步特征筛选的工作，我这里没有做特征的筛选，而且先复现了数据准备，模型构造和调参的过程。若是模型初步表现不错且较稳">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200924142454966.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JhYnkxNjAxdHJlZQ==,size_16,color_FFFFFF,t_70#pic_center">
<meta property="article:published_time" content="2023-04-24T08:04:20.032Z">
<meta property="article:modified_time" content="2023-04-24T08:18:21.858Z">
<meta property="article:author" content="小书包">
<meta property="article:tag" content="python">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="金融风控">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20200924142454966.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JhYnkxNjAxdHJlZQ==,size_16,color_FFFFFF,t_70#pic_center">

<link rel="canonical" href="http://example.com/2023/04/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83_%E9%87%91%E8%9E%8D%E9%A3%8E%E6%8E%A7_Task4_%E5%BB%BA%E6%A8%A1%E8%B0%83%E5%8F%82/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>机器学习训练_金融风控_Task4_建模调参 | 大宝的树屋</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="大宝的树屋" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

	<a target="_blank" rel="noopener" href="https://github.com/FelixBigTree" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#FD6C6C; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">大宝的树屋</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="download fa-fw"></i>资源</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/04/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83_%E9%87%91%E8%9E%8D%E9%A3%8E%E6%8E%A7_Task4_%E5%BB%BA%E6%A8%A1%E8%B0%83%E5%8F%82/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="小书包">
      <meta itemprop="description" content="种一棵树最好的时间是十年前，其次是现在">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="大宝的树屋">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习训练_金融风控_Task4_建模调参
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-04-24 16:04:20 / 修改时间：16:18:21" itemprop="dateCreated datePublished" datetime="2023-04-24T16:04:20+08:00">2023-04-24</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%87%91%E8%9E%8D%E9%A3%8E%E6%8E%A7/" itemprop="url" rel="index"><span itemprop="name">金融风控</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>27k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>25 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="序"><a href="#序" class="headerlink" title="序"></a>序</h1><p>特征工程之后，我们基本了解了数据集的概貌，通过缺失值处理、异常值处理、归一化、独热编码、特征构造等一系列方法对数据进行了预处理，并根据不同模型的数据要求对数据进行了一定的转化，从而进行下一步模型的学习过程。以下就是对数据进行处理后，训练模型的过程代码。其实可以先使用随机森林等方法先做一步特征筛选的工作，我这里没有做特征的筛选，而且先复现了数据准备，模型构造和调参的过程。若是模型初步表现不错且较稳定，我会后续做特征筛选或特征构造，进一步提高模型的分数。</p>
<h1 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h1><h2 id="导入第三方库"><a href="#导入第三方库" class="headerlink" title="导入第三方库"></a>导入第三方库</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, train_test_split, cross_val_score, GridSearchCV, StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">from</span> bayes_opt <span class="keyword">import</span> BayesianOptimization</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">sns 相关设置</span></span><br><span class="line"><span class="string">@return:</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># 声明使用 Seaborn 样式</span></span><br><span class="line"><span class="string">sns.set()</span></span><br><span class="line"><span class="string"># 有五种seaborn的绘图风格，它们分别是：darkgrid, whitegrid, dark, white, ticks。默认的主题是darkgrid。</span></span><br><span class="line"><span class="string">sns.set_style(&quot;whitegrid&quot;)</span></span><br><span class="line"><span class="string"># 有四个预置的环境，按大小从小到大排列分别为：paper, notebook, talk, poster。其中，notebook是默认的。</span></span><br><span class="line"><span class="string">sns.set_context(&#x27;talk&#x27;)</span></span><br><span class="line"><span class="string"># 中文字体设置-黑体</span></span><br><span class="line"><span class="string">plt.rcParams[&#x27;font.sans-serif&#x27;] = [&#x27;SimHei&#x27;]</span></span><br><span class="line"><span class="string"># 解决保存图像是负号&#x27;-&#x27;显示为方块的问题</span></span><br><span class="line"><span class="string">plt.rcParams[&#x27;axes.unicode_minus&#x27;] = False</span></span><br><span class="line"><span class="string"># 解决Seaborn中文显示问题并调整字体大小</span></span><br><span class="line"><span class="string">sns.set(font=&#x27;SimHei&#x27;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">pd.options.display.max_columns = <span class="literal">None</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.float_format&#x27;</span>, <span class="keyword">lambda</span> x: <span class="string">&#x27;%.2f&#x27;</span> % x)</span><br></pre></td></tr></table></figure>
<h2 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train = pd.read_csv(<span class="string">r&#x27;D:\Users\Felixteng\Documents\Pycharm Files\loanDefaultForecast\data\train.csv&#x27;</span>)</span><br><span class="line">testA = pd.read_csv(<span class="string">r&#x27;D:\Users\Felixteng\Documents\Pycharm Files\loanDefaultForecast\data\testA.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="压缩数据"><a href="#压缩数据" class="headerlink" title="压缩数据"></a>压缩数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">reduce_mem_usage</span>(<span class="params">df</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    遍历DataFrame的所有列并修改它们的数据类型以减少内存使用</span></span><br><span class="line"><span class="string">    :param df: 需要处理的数据集</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    start_mem = df.memory_usage().<span class="built_in">sum</span>() / <span class="number">1024</span> ** <span class="number">2</span>  <span class="comment"># 记录原数据的内存大小</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Memory usage of dataframe is &#123;:.2f&#125; MB&#x27;</span>.<span class="built_in">format</span>(start_mem))</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">        col_type = df[col].dtypes</span><br><span class="line">        <span class="keyword">if</span> col_type != <span class="built_in">object</span>:  <span class="comment"># 这里只过滤了object格式，如果代码中还包含其他类型，要一并过滤</span></span><br><span class="line">            c_min = df[col].<span class="built_in">min</span>()</span><br><span class="line">            c_max = df[col].<span class="built_in">max</span>()</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">str</span>(col_type)[:<span class="number">3</span>] == <span class="string">&#x27;int&#x27;</span>:  <span class="comment"># 如果是int类型的话,不管是int64还是int32,都加入判断</span></span><br><span class="line">                <span class="comment"># 依次尝试转化成in8,in16,in32,in64类型,如果数据大小没溢出,那么转化</span></span><br><span class="line">                <span class="keyword">if</span> c_min &gt; np.iinfo(np.int8).<span class="built_in">min</span> <span class="keyword">and</span> c_max &lt; np.iinfo(np.int8).<span class="built_in">max</span>:</span><br><span class="line">                    df[col] = df[col].astype(np.int8)</span><br><span class="line">                <span class="keyword">elif</span> c_min &gt; np.iinfo(np.int16).<span class="built_in">min</span> <span class="keyword">and</span> c_max &lt; np.iinfo(np.int16).<span class="built_in">max</span>:</span><br><span class="line">                    df[col] = df[col].astype(np.int16)</span><br><span class="line">                <span class="keyword">elif</span> c_min &gt; np.iinfo(np.int32).<span class="built_in">min</span> <span class="keyword">and</span> c_max &lt; np.iinfo(np.int32).<span class="built_in">max</span>:</span><br><span class="line">                    df[col] = df[col].astype(np.int32)</span><br><span class="line">                <span class="keyword">elif</span> c_min &gt; np.iinfo(np.int64).<span class="built_in">min</span> <span class="keyword">and</span> c_max &lt; np.iinfo(np.int64).<span class="built_in">max</span>:</span><br><span class="line">                    df[col] = df[col].astype(np.int64)</span><br><span class="line">            <span class="keyword">else</span>:  <span class="comment"># 不是整形的话,那就是浮点型</span></span><br><span class="line">                <span class="keyword">if</span> c_min &gt; np.finfo(np.float16).<span class="built_in">min</span> <span class="keyword">and</span> c_max &lt; np.finfo(np.float16).<span class="built_in">max</span>:</span><br><span class="line">                    df[col] = df[col].astype(np.float16)</span><br><span class="line">                <span class="keyword">elif</span> c_min &gt; np.finfo(np.float32).<span class="built_in">min</span> <span class="keyword">and</span> c_max &lt; np.finfo(np.float32).<span class="built_in">max</span>:</span><br><span class="line">                    df[col] = df[col].astype(np.float32)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    df[col] = df[col].astype(np.float64)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 如果不是数值型的话,转化成category类型</span></span><br><span class="line">            df[col] = df[col].astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    end_mem = df.memory_usage().<span class="built_in">sum</span>() / <span class="number">1024</span> ** <span class="number">2</span>    <span class="comment"># 看一下转化后的数据的内存大小</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Memory usage after optimization is &#123;:.2f&#125; MB&#x27;</span>.<span class="built_in">format</span>(end_mem))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Decreased by &#123;:.1f&#125;%&#x27;</span>.<span class="built_in">format</span>(<span class="number">100</span> * (start_mem - end_mem) / start_mem))  <span class="comment"># 看一下压缩比例</span></span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train = reduce_mem_usage(train)</span><br><span class="line">testA = reduce_mem_usage(testA)</span><br><span class="line"><span class="keyword">del</span> testA[<span class="string">&#x27;n2.2&#x27;</span>]</span><br><span class="line"><span class="keyword">del</span> testA[<span class="string">&#x27;n2.3&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h1 id="简单建模"><a href="#简单建模" class="headerlink" title="简单建模"></a>简单建模</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Tips1：金融风控的实际项目多涉及到信用评分，因此需要模型特征具有较好的可解释性，所以目前在实际项目中多还是以逻辑回归作为基础模型。</span></span><br><span class="line"><span class="string">        但是在比赛中以得分高低为准，不需要严谨的可解释性，所以大多基于集成算法进行建模。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Tips2：因为逻辑回归的算法特性，需要提前对异常值、缺失值数据进行处理(参考task3部分)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Tips3：基于树模型的算法特性，异常值、缺失值处理可以跳过，但是对于业务较为了解的同学也可以自己对缺失异常值进行处理，效果可能会更优于模型处理的结果。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">注：以下建模的源数据参考baseline进行了相应的特征工程，对于异常缺失值未进行相应的处理操作</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="建模之前的数据处理"><a href="#建模之前的数据处理" class="headerlink" title="建模之前的数据处理"></a>建模之前的数据处理</h2><p>为了方便起见，把训练集和测试集合并处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = pd.concat([train, testA], axis=<span class="number">0</span>, ignore_index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>category特征不能直接训练，需要处理转换</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[&#x27;grade&#x27;, &#x27;subGrade&#x27;, &#x27;employmentLength&#x27;, &#x27;issueDate&#x27;, &#x27;earliesCreditLine&#x27;]</span></span><br><span class="line"><span class="string">先处理&#x27;employmentLength&#x27;, &#x27;issueDate&#x27;, &#x27;earliesCreditLine&#x27;这三个特征；&#x27;grade&#x27;和&#x27;subGrade&#x27;做one-hot编码</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="‘employmentLength’-转换为数值"><a href="#‘employmentLength’-转换为数值" class="headerlink" title="‘employmentLength’ - 转换为数值"></a>‘employmentLength’ - 转换为数值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">data.groupby(<span class="string">&#x27;employmentLength&#x27;</span>)[<span class="string">&#x27;id&#x27;</span>].count()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;10年以上算10年，1年一下算0年&#x27;&#x27;&#x27;</span></span><br><span class="line">data[<span class="string">&#x27;employmentLength&#x27;</span>].replace(to_replace=<span class="string">&#x27;10+ years&#x27;</span>, value=<span class="string">&#x27;10 years&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">data[<span class="string">&#x27;employmentLength&#x27;</span>].replace(to_replace=<span class="string">&#x27;&lt; 1 year&#x27;</span>, value=<span class="string">&#x27;0 year&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">employmentLength_to_int</span>(<span class="params">s</span>):</span><br><span class="line">    <span class="keyword">if</span> pd.isnull(s):</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> np.int8(s.split()[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">data[<span class="string">&#x27;employmentLength&#x27;</span>] = data[<span class="string">&#x27;employmentLength&#x27;</span>].apply(employmentLength_to_int)</span><br></pre></td></tr></table></figure>
<h3 id="‘earliesCreditLine’-分别提取年份和月份做拼接"><a href="#‘earliesCreditLine’-分别提取年份和月份做拼接" class="headerlink" title="‘earliesCreditLine’ - 分别提取年份和月份做拼接"></a>‘earliesCreditLine’ - 分别提取年份和月份做拼接</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">&#x27;earliesCreditLine_year&#x27;</span>] = data[<span class="string">&#x27;earliesCreditLine&#x27;</span>].apply(<span class="keyword">lambda</span> x: x[-<span class="number">4</span>:])</span><br><span class="line">data[<span class="string">&#x27;earliesCreditLine_month&#x27;</span>] = data[<span class="string">&#x27;earliesCreditLine&#x27;</span>].apply(<span class="keyword">lambda</span> x: x[<span class="number">0</span>:<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">month_re</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">if</span> x == <span class="string">&#x27;Jan&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;01&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> x == <span class="string">&#x27;Feb&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;02&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> x == <span class="string">&#x27;Mar&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;03&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> x == <span class="string">&#x27;Apr&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;04&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> x == <span class="string">&#x27;May&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;05&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> x == <span class="string">&#x27;Jun&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;06&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> x == <span class="string">&#x27;Jul&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;07&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> x == <span class="string">&#x27;Aug&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;08&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> x == <span class="string">&#x27;Sep&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;09&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> x == <span class="string">&#x27;Oct&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;10&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> x == <span class="string">&#x27;Nov&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;11&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;12&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data[<span class="string">&#x27;earliesCreditLine_month&#x27;</span>] = data[<span class="string">&#x27;earliesCreditLine_month&#x27;</span>].apply(<span class="keyword">lambda</span> x: month_re(x))</span><br><span class="line">data[<span class="string">&#x27;earliesCreditLine_date&#x27;</span>] = data[<span class="string">&#x27;earliesCreditLine_year&#x27;</span>] + data[<span class="string">&#x27;earliesCreditLine_month&#x27;</span>]</span><br><span class="line">data[<span class="string">&#x27;earliesCreditLine_date&#x27;</span>] = data[<span class="string">&#x27;earliesCreditLine_date&#x27;</span>].astype(<span class="string">&#x27;int&#x27;</span>)</span><br><span class="line"><span class="keyword">del</span> data[<span class="string">&#x27;earliesCreditLine&#x27;</span>]</span><br><span class="line"><span class="keyword">del</span> data[<span class="string">&#x27;earliesCreditLine_year&#x27;</span>]</span><br><span class="line"><span class="keyword">del</span> data[<span class="string">&#x27;earliesCreditLine_month&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h3 id="‘issueDate’-从数据可以看出，issueDate从2017年6月1日开始；数据按照此节点统计天数"><a href="#‘issueDate’-从数据可以看出，issueDate从2017年6月1日开始；数据按照此节点统计天数" class="headerlink" title="‘issueDate’ - 从数据可以看出，issueDate从2017年6月1日开始；数据按照此节点统计天数"></a>‘issueDate’ - 从数据可以看出，issueDate从2017年6月1日开始；数据按照此节点统计天数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">&#x27;issueDate&#x27;</span>] = pd.to_datetime(data[<span class="string">&#x27;issueDate&#x27;</span>], <span class="built_in">format</span>=<span class="string">&#x27;%Y-%m-%d&#x27;</span>)</span><br><span class="line">startdate = datetime.datetime.strptime(<span class="string">&#x27;2007-06-01&#x27;</span>, <span class="string">&#x27;%Y-%m-%d&#x27;</span>)</span><br><span class="line">data[<span class="string">&#x27;issueDateDt&#x27;</span>] = data[<span class="string">&#x27;issueDate&#x27;</span>].apply(<span class="keyword">lambda</span> x: x - startdate).dt.days</span><br><span class="line"><span class="keyword">del</span> data[<span class="string">&#x27;issueDate&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>除了本身是category类型的特征，还有一些数值特征表现出的也是类别型的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;将1类以上且非高维稀疏的特征进行one-hot编码&#x27;&#x27;&#x27;</span></span><br><span class="line">cate_features = [<span class="string">&#x27;grade&#x27;</span>, <span class="string">&#x27;subGrade&#x27;</span>, <span class="string">&#x27;employmentTitle&#x27;</span>, <span class="string">&#x27;homeOwnership&#x27;</span>, <span class="string">&#x27;verificationStatus&#x27;</span>, <span class="string">&#x27;purpose&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;postCode&#x27;</span>, <span class="string">&#x27;regionCode&#x27;</span>, <span class="string">&#x27;applicationType&#x27;</span>, <span class="string">&#x27;initialListStatus&#x27;</span>, <span class="string">&#x27;title&#x27;</span>, <span class="string">&#x27;policyCode&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> cate <span class="keyword">in</span> cate_features:</span><br><span class="line">    <span class="built_in">print</span>(cate, <span class="string">&#x27;类型数&#x27;</span>, data[cate].nunique())</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">grade 类型数 7</span></span><br><span class="line"><span class="string">subGrade 类型数 35</span></span><br><span class="line"><span class="string">employmentTitle 类型数 298101</span></span><br><span class="line"><span class="string">homeOwnership 类型数 6</span></span><br><span class="line"><span class="string">verificationStatus 类型数 3</span></span><br><span class="line"><span class="string">purpose 类型数 14</span></span><br><span class="line"><span class="string">postCode 类型数 935</span></span><br><span class="line"><span class="string">regionCode 类型数 51</span></span><br><span class="line"><span class="string">applicationType 类型数 2</span></span><br><span class="line"><span class="string">initialListStatus 类型数 2</span></span><br><span class="line"><span class="string">title 类型数 6712</span></span><br><span class="line"><span class="string">policyCode 类型数 1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">不适合做one-hot编码的是</span></span><br><span class="line"><span class="string">    employmentTitle 类型数 298101</span></span><br><span class="line"><span class="string">    postCode 类型数 935</span></span><br><span class="line"><span class="string">    title 类型数 6712</span></span><br><span class="line"><span class="string">    regionCode 类型数 51 - 大于50的先不处理了，维度还是比较高的</span></span><br><span class="line"><span class="string">    policyCode 类型数 1 - 无分析价值，可直接删除</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">del</span> data[<span class="string">&#x27;policyCode&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h2 id="one-hot编码"><a href="#one-hot编码" class="headerlink" title="one-hot编码"></a>one-hot编码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = pd.get_dummies(data, columns=[<span class="string">&#x27;grade&#x27;</span>, <span class="string">&#x27;subGrade&#x27;</span>, <span class="string">&#x27;homeOwnership&#x27;</span>, <span class="string">&#x27;verificationStatus&#x27;</span>,</span><br><span class="line">                                     <span class="string">&#x27;purpose&#x27;</span>, <span class="string">&#x27;applicationType&#x27;</span>, <span class="string">&#x27;initialListStatus&#x27;</span>], drop_first=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>对于高维类别特征，进行转换，取他们同类型的数量值和排名值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> [<span class="string">&#x27;employmentTitle&#x27;</span>, <span class="string">&#x27;postCode&#x27;</span>, <span class="string">&#x27;regionCode&#x27;</span>, <span class="string">&#x27;title&#x27;</span>]:</span><br><span class="line">    data[f + <span class="string">&#x27;_counts&#x27;</span>] = data.groupby([f])[<span class="string">&#x27;id&#x27;</span>].transform(<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line">    data[f + <span class="string">&#x27;_rank&#x27;</span>] = data.groupby([f])[<span class="string">&#x27;id&#x27;</span>].rank(ascending=<span class="literal">False</span>).astype(<span class="built_in">int</span>)</span><br><span class="line">    <span class="keyword">del</span> data[f]</span><br></pre></td></tr></table></figure>
<h2 id="准备训练集和测试集"><a href="#准备训练集和测试集" class="headerlink" title="准备训练集和测试集"></a>准备训练集和测试集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">features = [f <span class="keyword">for</span> f <span class="keyword">in</span> data.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;isDefault&#x27;</span>]]</span><br><span class="line">train = data[data.isDefault.notnull()].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">testA = data[data.isDefault.isnull()].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">x_train = train[features]</span><br><span class="line">y_train = train[<span class="string">&#x27;isDefault&#x27;</span>]</span><br><span class="line">x_testA = testA[features]</span><br></pre></td></tr></table></figure>
<h2 id="五折交叉验证准备"><a href="#五折交叉验证准备" class="headerlink" title="五折交叉验证准备"></a>五折交叉验证准备</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">folds = <span class="number">5</span></span><br><span class="line">seed = <span class="number">2020</span></span><br><span class="line">kf = KFold(n_splits=folds, shuffle=<span class="literal">True</span>, random_state=seed)</span><br></pre></td></tr></table></figure>
<h1 id="建模-Lightgbm"><a href="#建模-Lightgbm" class="headerlink" title="建模 - Lightgbm"></a>建模 - Lightgbm</h1><h2 id="将训练集分为5份，4份作为训练集，1份作为验证集"><a href="#将训练集分为5份，4份作为训练集，1份作为验证集" class="headerlink" title="将训练集分为5份，4份作为训练集，1份作为验证集"></a>将训练集分为5份，4份作为训练集，1份作为验证集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train_split, X_val, y_train_split, y_val = train_test_split(x_train, y_train, test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<p>将数据集转化成能用于lgb训练的形式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_split_matrix = lgb.Dataset(X_train_split, label=y_train_split)</span><br><span class="line">val_matrix = lgb.Dataset(X_val, label=y_val)</span><br></pre></td></tr></table></figure>
<p>初步自定义lgb参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;boosting_type&#x27;</span>: <span class="string">&#x27;gbdt&#x27;</span>, <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;binary&#x27;</span>, <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;metric&#x27;</span>: <span class="string">&#x27;auc&#x27;</span>, <span class="string">&#x27;min_child_weight&#x27;</span>: <span class="number">1e-3</span>,</span><br><span class="line">    <span class="string">&#x27;num_leaves&#x27;</span>: <span class="number">31</span>, <span class="string">&#x27;max_depth&#x27;</span>: -<span class="number">1</span>, <span class="string">&#x27;reg_lambda&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;reg_alpha&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;feature_fraction&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;bagging_fraction&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">&#x27;bagging_freq&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;seed&#x27;</span>: <span class="number">2020</span>, <span class="string">&#x27;nthread&#x27;</span>: <span class="number">8</span>, <span class="string">&#x27;verbose&#x27;</span>: -<span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>将训练集丢入lgb模型训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model = lgb.train(params, train_set=train_split_matrix, valid_sets=val_matrix, num_boost_round=<span class="number">20000</span>,</span><br><span class="line">                  verbose_eval=<span class="number">1000</span>, early_stopping_rounds=<span class="number">200</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Training until validation scores don&#x27;t improve for 200 rounds</span></span><br><span class="line"><span class="string">Early stopping, best iteration is:</span></span><br><span class="line"><span class="string">[419]	valid_0&#x27;s auc: 0.735017</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>用训练好的模型预测验证集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val_pre_lgb = model.predict(X_val, num_iteration=model.best_iteration)</span><br></pre></td></tr></table></figure>
<p>计算roc的相关指标</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">真正类率(True Positive Rate)TPR: TP / (TP + FN),代表分类器预测的正类中实际正实例占所有正实例的比例</span></span><br><span class="line"><span class="string">纵轴TPR：TPR越大，预测正类中实际正类越多</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">负正类率(False Positive Rate)FPR: FP / (FP + TN)，代表分类器预测的正类中实际负实例占所有负实例的比例</span></span><br><span class="line"><span class="string">横轴FPR:FPR越大，预测正类中实际负类越多</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">理想目标：TPR=1，FPR=0,即roc图中的(0,1)点，故ROC曲线越靠拢(0,1)点，越偏离45度对角线越好，Sensitivity、Specificity越大效果越好</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fpr, tpr, threshold = metrics.roc_curve(y_val, val_pre_lgb)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;未调参前lgb在验证集上的AUC： &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(roc_auc))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;未调参前lgb在验证集上的AUC： 0.7350165705811689&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>画出roc曲线</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;Val ROC&#x27;</span>)</span><br><span class="line">plt.plot(fpr, tpr, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Val AUC = %0.4f&#x27;</span> % roc_auc)  <span class="comment"># 保留四位小数</span></span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">plt.xlim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True Positive Rate&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;False Positive Rate&#x27;</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], <span class="string">&#x27;r--&#x27;</span>)     <span class="comment"># 对角线</span></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20200924142454966.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JhYnkxNjAxdHJlZQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>使用5折交叉验证进行模型性能评估</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">cv_scores = []  <span class="comment"># 用于存放每次验证的得分</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ## 五折交叉验证评估模型</span></span><br><span class="line"><span class="keyword">for</span> i, (train_index, val_index) <span class="keyword">in</span> <span class="built_in">enumerate</span>(kf.split(x_train, y_train)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;*** &#123;&#125; ***&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(i+<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">    X_train_split, y_train_split, X_val, y_val = x_train.iloc[train_index], y_train[train_index], \</span><br><span class="line">                                                 x_train.iloc[val_index], y_train[val_index]</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;划分训练集和验证集&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    train_matrix = lgb.Dataset(X_train_split, label=y_train_split)</span><br><span class="line">    val_matrix = lgb.Dataset(X_val, label=y_val)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;转换成lgb训练的数据形式&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;boosting_type&#x27;</span>: <span class="string">&#x27;gbdt&#x27;</span>, <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;binary&#x27;</span>, <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;metric&#x27;</span>: <span class="string">&#x27;auc&#x27;</span>, <span class="string">&#x27;min_child_weight&#x27;</span>: <span class="number">1e-3</span>,</span><br><span class="line">        <span class="string">&#x27;num_leaves&#x27;</span>: <span class="number">31</span>, <span class="string">&#x27;max_depth&#x27;</span>: -<span class="number">1</span>, <span class="string">&#x27;reg_lambda&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;reg_alpha&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;feature_fraction&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;bagging_fraction&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;bagging_freq&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;seed&#x27;</span>: <span class="number">2020</span>, <span class="string">&#x27;nthread&#x27;</span>: <span class="number">8</span>, <span class="string">&#x27;verbose&#x27;</span>: -<span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;给定lgb参数&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    model = lgb.train(params, train_set=train_matrix, num_boost_round=<span class="number">20000</span>, valid_sets=val_matrix, verbose_eval=<span class="number">1000</span>,</span><br><span class="line">                      early_stopping_rounds=<span class="number">200</span>)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;训练模型&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    val_pre_lgb = model.predict(X_val, num_iteration=model.best_iteration)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;预测验证集结果&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    cv_scores.append(roc_auc_score(y_val, val_pre_lgb))</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;将auc加入列表&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(cv_scores)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">*** 1 ***</span></span><br><span class="line"><span class="string">Training until validation scores don&#x27;t improve for 200 rounds</span></span><br><span class="line"><span class="string">Early stopping, best iteration is:</span></span><br><span class="line"><span class="string">[480]	valid_0&#x27;s auc: 0.735706</span></span><br><span class="line"><span class="string">[0.7357056028032594]</span></span><br><span class="line"><span class="string">*** 2 ***</span></span><br><span class="line"><span class="string">Training until validation scores don&#x27;t improve for 200 rounds</span></span><br><span class="line"><span class="string">Early stopping, best iteration is:</span></span><br><span class="line"><span class="string">[394]	valid_0&#x27;s auc: 0.732804</span></span><br><span class="line"><span class="string">[0.7357056028032594, 0.7328044319912592]</span></span><br><span class="line"><span class="string">*** 3 ***</span></span><br><span class="line"><span class="string">Training until validation scores don&#x27;t improve for 200 rounds</span></span><br><span class="line"><span class="string">Early stopping, best iteration is:</span></span><br><span class="line"><span class="string">[469]	valid_0&#x27;s auc: 0.736296</span></span><br><span class="line"><span class="string">[0.7357056028032594, 0.7328044319912592, 0.736295686606251]</span></span><br><span class="line"><span class="string">*** 4 ***</span></span><br><span class="line"><span class="string">Training until validation scores don&#x27;t improve for 200 rounds</span></span><br><span class="line"><span class="string">Early stopping, best iteration is:</span></span><br><span class="line"><span class="string">[480]	valid_0&#x27;s auc: 0.735153</span></span><br><span class="line"><span class="string">[0.7357056028032594, 0.7328044319912592, 0.736295686606251, 0.7351530881059898]</span></span><br><span class="line"><span class="string">*** 5 ***</span></span><br><span class="line"><span class="string">Training until validation scores don&#x27;t improve for 200 rounds</span></span><br><span class="line"><span class="string">Early stopping, best iteration is:</span></span><br><span class="line"><span class="string">[481]	valid_0&#x27;s auc: 0.734523</span></span><br><span class="line"><span class="string">[0.7357056028032594, 0.7328044319912592, 0.736295686606251, 0.7351530881059898, 0.7345226943030314]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h1 id="调参"><a href="#调参" class="headerlink" title="调参"></a>调参</h1><h2 id="贪心调参"><a href="#贪心调参" class="headerlink" title="贪心调参"></a>贪心调参</h2><p>先使用当前对模型影响最大的参数进行调优，达到当前参数下的模型最优化，再使用对模型影响次之的参数进行调优，如此下去，直到所有的参数调整完毕。<br>这个方法的缺点就是可能会调到局部最优而不是全局最优，但是只需要一步一步的进行参数最优化调试即可，容易理解。<br>需要注意的是在树模型中参数调整的顺序，也就是各个参数对模型的影响程度，列举一下日常调参过程中常用的参数和调参顺序:<br>    max_depth、num_leaves<br>    min_data_in_leaf、min_child_weight<br>    bagging_fraction、 feature_fraction、bagging_freq<br>    reg_lambda、reg_alpha<br>    min_split_gain</p>
<h3 id="objective"><a href="#objective" class="headerlink" title="objective"></a>objective</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">best_obj = <span class="built_in">dict</span>()</span><br><span class="line">objective = [<span class="string">&#x27;regression&#x27;</span>, <span class="string">&#x27;regression_l2&#x27;</span>, <span class="string">&#x27;regression_l1&#x27;</span>, <span class="string">&#x27;huber&#x27;</span>, <span class="string">&#x27;fair&#x27;</span>, <span class="string">&#x27;poisson&#x27;</span>,</span><br><span class="line">             <span class="string">&#x27;binary&#x27;</span>, <span class="string">&#x27;lambdarank&#x27;</span>, <span class="string">&#x27;multiclass&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> obj <span class="keyword">in</span> objective:</span><br><span class="line">    model = lgb.LGBMRegressor(objective=obj)</span><br><span class="line">    score = cross_val_score(model, x_train, y_train, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;roc_auc&#x27;</span>).mean()</span><br><span class="line">    best_obj[obj] = score</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;针对每种学习目标参数，分别把5次交叉验证的结果取平均值放入字典&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;&#x27;regression&#x27;: 0.7317571771311902, &#x27;regression_l2&#x27;: 0.7317571771311902, &#x27;regression_l1&#x27;: 0.5254673662915372, </span></span><br><span class="line"><span class="string">&#x27;huber&#x27;: 0.7317930010205694, &#x27;fair&#x27;: 0.7299013530452948, &#x27;poisson&#x27;: 0.7276315321558192, </span></span><br><span class="line"><span class="string">&#x27;binary&#x27;: 0.7325703837580402, &#x27;lambdarank&#x27;: nan, &#x27;multiclass&#x27;: nan&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">分数最高的objective是&#x27;binary&#x27;: 0.7325703837580402</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="max-depth"><a href="#max-depth" class="headerlink" title="max_depth"></a>max_depth</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">best_depth = <span class="built_in">dict</span>()</span><br><span class="line">max_depth = [<span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">12</span>]</span><br><span class="line"><span class="keyword">for</span> depth <span class="keyword">in</span> max_depth:</span><br><span class="line">    model = lgb.LGBMRegressor(objective=<span class="string">&#x27;binary&#x27;</span>, max_depth=depth)</span><br><span class="line">    score = cross_val_score(model, x_train, y_train, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;roc_auc&#x27;</span>).mean()</span><br><span class="line">    best_depth[depth] = score</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;4: 0.7289917272476384, 6: 0.7318582290988798, 8: 0.7326689825432566, </span></span><br><span class="line"><span class="string">10: 0.7327216337284277, 12: 0.7326861296973519&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">分数最高的depth是 10: 0.7327216337284277</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="num-leaves-为了防止过拟合，num-leaves要小于2-max-depth-2-10-x3D-1024"><a href="#num-leaves-为了防止过拟合，num-leaves要小于2-max-depth-2-10-x3D-1024" class="headerlink" title="num_leaves - 为了防止过拟合，num_leaves要小于2^max_depth(2^10&#x3D;1024)"></a>num_leaves - 为了防止过拟合，num_leaves要小于2^max_depth(2^10&#x3D;1024)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">best_leaves = <span class="built_in">dict</span>()</span><br><span class="line">num_leaves = [<span class="number">60</span>, <span class="number">80</span>, <span class="number">100</span>, <span class="number">120</span>, <span class="number">140</span>, <span class="number">160</span>, <span class="number">180</span>, <span class="number">200</span>]</span><br><span class="line"><span class="keyword">for</span> leaf <span class="keyword">in</span> num_leaves:</span><br><span class="line">    model = lgb.LGBMRegressor(objective=<span class="string">&#x27;binary&#x27;</span>, max_depth=<span class="number">10</span>, num_leaves=leaf)</span><br><span class="line">    score = cross_val_score(model, x_train, y_train, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;roc_auc&#x27;</span>).mean()</span><br><span class="line">    best_leaves[leaf] = score</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;60: 0.7338063124202595, 80: 0.7340086888735147, 100: 0.7340517113255459, 120: 0.7339504337283304, </span></span><br><span class="line"><span class="string">140: 0.733943621732856, 160: 0.7340382165600425, 180: 0.7335684540056998, 200: 0.7331373764276772&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">分数最高的num_leaves是 num_leaves 100: 0.7340517113255459</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="min-data-in-leaf"><a href="#min-data-in-leaf" class="headerlink" title="min_data_in_leaf"></a>min_data_in_leaf</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">best_min_leaves = <span class="built_in">dict</span>()</span><br><span class="line">min_data_in_leaf = [<span class="number">14</span>, <span class="number">18</span>, <span class="number">22</span>, <span class="number">26</span>, <span class="number">30</span>, <span class="number">34</span>]</span><br><span class="line"><span class="keyword">for</span> min_leaf <span class="keyword">in</span> min_data_in_leaf:</span><br><span class="line">    model = lgb.LGBMRegressor(objective=<span class="string">&#x27;binary&#x27;</span>, max_depth=<span class="number">10</span>, num_leaves=<span class="number">100</span>, min_data_in_leaf=min_leaf)</span><br><span class="line">    score = cross_val_score(model, x_train, y_train, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;roc_auc&#x27;</span>).mean()</span><br><span class="line">    best_min_leaves[min_leaf] = score</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;14: 0.7338644336034048, 18: 0.7340150561766138, 22: 0.7340158598138881, 26: 0.7341871752335695, </span></span><br><span class="line"><span class="string">30: 0.7340615684229571, 34: 0.7340519101378781&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">分数最高的 min_leaf是 26: 0.7341871752335695</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="min-child-weight"><a href="#min-child-weight" class="headerlink" title="min_child_weight"></a>min_child_weight</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">best_weight = <span class="built_in">dict</span>()</span><br><span class="line">min_child_weight = [<span class="number">0.002</span>, <span class="number">0.004</span>, <span class="number">0.006</span>, <span class="number">0.008</span>, <span class="number">0.010</span>, <span class="number">0.012</span>]</span><br><span class="line"><span class="keyword">for</span> min_weight <span class="keyword">in</span> min_child_weight:</span><br><span class="line">    model = lgb.LGBMRegressor(objective=<span class="string">&#x27;binary&#x27;</span>, max_depth=<span class="number">10</span>, num_leaves=<span class="number">100</span>, min_data_in_leaf=<span class="number">26</span>,</span><br><span class="line">                              min_child_weight=min_weight)</span><br><span class="line">    score = cross_val_score(model, x_train, y_train, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;roc_auc&#x27;</span>).mean()</span><br><span class="line">    best_weight[min_weight] = score</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;0.002: 0.7341871752335695, 0.004: 0.7341871752335695, 0.006: 0.7341871752335695, 0.008: 0.7341871752335695, </span></span><br><span class="line"><span class="string">0.01: 0.7341871752335695, 0.012: 0.7341871752335695&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">都一样，说明min_data_in_leaf和min_child_weight应该是对应的？</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="bagging-fraction-bagging-freq"><a href="#bagging-fraction-bagging-freq" class="headerlink" title="bagging_fraction + bagging_freq"></a>bagging_fraction + bagging_freq</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">bagging_fraction+bagging_freq参数必须同时设置，bagging_fraction相当于subsample样本采样，可以使bagging更快的运行，同时也可以降拟合。</span></span><br><span class="line"><span class="string">bagging_freq默认0，表示bagging的频率，0意味着没有使用bagging，k意味着每k轮迭代进行一次bagging</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">best_bagging_fraction = <span class="built_in">dict</span>()</span><br><span class="line">bagging_fraction = [<span class="number">0.5</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">0.95</span>]</span><br><span class="line"><span class="keyword">for</span> bagging <span class="keyword">in</span> bagging_fraction:</span><br><span class="line">    model = lgb.LGBMRegressor(objective=<span class="string">&#x27;binary&#x27;</span>, max_depth=<span class="number">10</span>, num_leaves=<span class="number">100</span>, min_data_in_leaf=<span class="number">26</span>,</span><br><span class="line">                              bagging_fraction=bagging)</span><br><span class="line">    score = cross_val_score(model, x_train, y_train, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;roc_auc&#x27;</span>).mean()</span><br><span class="line">    best_bagging_fraction[bagging] = score</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;0.5: 0.7341871752335695, 0.6: 0.734187175233</span></span><br><span class="line"><span class="string">5695, 0.7: 0.7341871752335695, 0.8: 0.7341871752335695, 0.9: 0.7341871752335695, 0.95: 0.7341871752335695&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">没变化</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="feature-fraction"><a href="#feature-fraction" class="headerlink" title="feature_fraction"></a>feature_fraction</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">best_feature_fraction = <span class="built_in">dict</span>()</span><br><span class="line">feature_fraction = [<span class="number">0.5</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">0.95</span>]</span><br><span class="line"><span class="keyword">for</span> feature <span class="keyword">in</span> feature_fraction:</span><br><span class="line">    model = lgb.LGBMRegressor(objective=<span class="string">&#x27;binary&#x27;</span>, max_depth=<span class="number">10</span>, num_leaves=<span class="number">100</span>, min_data_in_leaf=<span class="number">26</span>,</span><br><span class="line">                              feature_fraction=feature)</span><br><span class="line">    score = cross_val_score(model, x_train, y_train, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;roc_auc&#x27;</span>).mean()</span><br><span class="line">    best_feature_fraction[feature] = score</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;0.5: 0.7341332691040499, 0.6: 0.7342461204659492, 0.7: 0.7340950793860553, 0.8: 0.734168394330798, </span></span><br><span class="line"><span class="string">0.9: 0.7342417001187209, 0.95: 0.7340419425131396&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">虽然0.6会高一些，但是出于样本特征的使用率我还是想用0.9</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="reg-lambda"><a href="#reg-lambda" class="headerlink" title="reg_lambda"></a>reg_lambda</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">best_reg_lambda = <span class="built_in">dict</span>()</span><br><span class="line">reg_lambda = [<span class="number">0</span>, <span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.03</span>, <span class="number">0.08</span>, <span class="number">0.3</span>, <span class="number">0.5</span>]</span><br><span class="line"><span class="keyword">for</span> lam <span class="keyword">in</span> reg_lambda:</span><br><span class="line">    model = lgb.LGBMRegressor(objective=<span class="string">&#x27;binary&#x27;</span>, max_depth=<span class="number">10</span>, num_leaves=<span class="number">100</span>, min_data_in_leaf=<span class="number">26</span>,</span><br><span class="line">                              feature_fraction=<span class="number">0.9</span>, reg_lambda=lam)</span><br><span class="line">    score = cross_val_score(model, x_train, y_train, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;roc_auc&#x27;</span>).mean()</span><br><span class="line">    best_reg_lambda[lam] = score</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;0: 0.7342417001187209, 0.001: 0.7340521878374329, 0.01: 0.7342087379791171, </span></span><br><span class="line"><span class="string">0.03: 0.7342072587501143, 0.08: 0.7341178131960189, 0.3: 0.7342923823693306, 0.5: 0.7342815855243002&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">reg_lambda 最优值为 0.3: 0.7342923823693306</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="reg-alpha"><a href="#reg-alpha" class="headerlink" title="reg_alpha"></a>reg_alpha</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">best_reg_alpha = <span class="built_in">dict</span>()</span><br><span class="line">reg_alpha = [<span class="number">0</span>, <span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.03</span>, <span class="number">0.08</span>, <span class="number">0.3</span>, <span class="number">0.5</span>]</span><br><span class="line"><span class="keyword">for</span> alp <span class="keyword">in</span> reg_alpha:</span><br><span class="line">    model = lgb.LGBMRegressor(objective=<span class="string">&#x27;binary&#x27;</span>, max_depth=<span class="number">10</span>, num_leaves=<span class="number">100</span>, min_data_in_leaf=<span class="number">26</span>,</span><br><span class="line">                              feature_fraction=<span class="number">0.9</span>, reg_lambda=<span class="number">0.3</span>, reg_alpha=alp)</span><br><span class="line">    score = cross_val_score(model, x_train, y_train, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;roc_auc&#x27;</span>).mean()</span><br><span class="line">    best_reg_alpha[alp] = score</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;0: 0.7342923823693306, 0.001: 0.7342141300723407, 0.01: 0.7342716599336013, 0.03: 0.7342356374031566, </span></span><br><span class="line"><span class="string">0.08: 0.7342509380457417, 0.3: 0.7341836259662214, 0.5: 0.7342654379571296&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">reg_alpha 为0时最高</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="learning-rate"><a href="#learning-rate" class="headerlink" title="learning_rate"></a>learning_rate</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">best_learning_rate = <span class="built_in">dict</span>()</span><br><span class="line">learning_rate = [<span class="number">0.01</span>, <span class="number">0.05</span>, <span class="number">0.08</span>, <span class="number">0.1</span>, <span class="number">0.12</span>]</span><br><span class="line"><span class="keyword">for</span> learn <span class="keyword">in</span> learning_rate:</span><br><span class="line">    model = lgb.LGBMRegressor(objective=<span class="string">&#x27;binary&#x27;</span>, max_depth=<span class="number">10</span>, num_leaves=<span class="number">100</span>, min_data_in_leaf=<span class="number">26</span>,</span><br><span class="line">                              feature_fraction=<span class="number">0.9</span>, reg_lambda=<span class="number">0.3</span>, learning_rate=learn)</span><br><span class="line">    score = cross_val_score(model, x_train, y_train, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;roc_auc&#x27;</span>).mean()</span><br><span class="line">    best_learning_rate[learn] = score</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;0.01: 0.719100817422237, 0.05: 0.7315198412233572, 0.08: 0.733713956417723, 0.1: 0.7342923823693306, </span></span><br><span class="line"><span class="string">0.12: 0.7341688215024998&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">learning_rate 为0.1时最好</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="网格调参"><a href="#网格调参" class="headerlink" title="网格调参"></a>网格调参</h2><p>网格调参+五折交叉验证非常非常非常耗时，建议开始步长选大一点，我步长较小，导致调参耗时非常可怕</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">sklearn 提供GridSearchCV用于进行网格搜索，只需要把模型的参数输进去，就能给出最优化的结果和参数。</span></span><br><span class="line"><span class="string">相比起贪心调参，网格搜索的结果会更优，但是网格搜索只适合于小数据集，一旦数据的量级上去了，很难得出结果</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_best_cv_params</span>(<span class="params">learning_rate=<span class="number">0.1</span>, n_estimators=<span class="number">800</span>, num_leaves=<span class="number">100</span>, max_depth=<span class="number">10</span>, feature_fraction=<span class="number">0.9</span>,</span></span><br><span class="line"><span class="params">                       min_data_in_leaf=<span class="number">26</span>, reg_lambda=<span class="number">0.3</span>, reg_alpha=<span class="number">0</span>, objective=<span class="string">&#x27;binary&#x27;</span>, param_grid=<span class="literal">None</span></span>):</span><br><span class="line">    cv_fold = StratifiedKFold(n_splits=<span class="number">5</span>, random_state=<span class="number">2020</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;设置五折交叉验证&#x27;&#x27;&#x27;</span></span><br><span class="line">    model_lgb = lgb.LGBMRegressor(learning_rate=learning_rate, n_estimators=n_estimators, num_leaves=num_leaves,</span><br><span class="line">                                  max_depth=max_depth, feature_fraction=feature_fraction,</span><br><span class="line">                                  min_data_in_leaf=min_data_in_leaf, reg_lambda=reg_lambda, reg_alpha=reg_alpha,</span><br><span class="line">                                  objective=objective, n_jobs=-<span class="number">1</span>)</span><br><span class="line">    grid_search = GridSearchCV(estimator=model_lgb, cv=cv_fold, param_grid=param_grid, scoring=<span class="string">&#x27;roc_auc&#x27;</span>)</span><br><span class="line">    grid_search.fit(x_train, y_train)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;模型当前最优参数为： &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(grid_search.best_params_))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;模型当前最优得分为： &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(grid_search.best_score_))</span><br></pre></td></tr></table></figure>
<h3 id="先调-max-depth和-num-leaves"><a href="#先调-max-depth和-num-leaves" class="headerlink" title="先调 max_depth和 num_leaves"></a>先调 max_depth和 num_leaves</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lgb_params = &#123;<span class="string">&#x27;num_leaves&#x27;</span>: <span class="built_in">range</span>(<span class="number">80</span>, <span class="number">120</span>, <span class="number">5</span>), <span class="string">&#x27;max_depth&#x27;</span>: <span class="built_in">range</span>(<span class="number">6</span>, <span class="number">14</span>, <span class="number">2</span>)&#125;</span><br><span class="line">get_best_cv_params(param_grid=lgb_params)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">模型当前最优参数为： &#123;&#x27;max_depth&#x27;: 6, &#x27;num_leaves&#x27;: 80&#125;</span></span><br><span class="line"><span class="string">模型当前最优得分为： 0.7349883936428184</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="min-data-in-leaf和min-child-weight"><a href="#min-data-in-leaf和min-child-weight" class="headerlink" title="min_data_in_leaf和min_child_weight"></a>min_data_in_leaf和min_child_weight</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lgb_params = &#123;<span class="string">&#x27;min_data_in_leaf&#x27;</span>: <span class="built_in">range</span>(<span class="number">20</span>, <span class="number">60</span>, <span class="number">5</span>)&#125;</span><br><span class="line">get_best_cv_params(param_grid=lgb_params, max_depth=<span class="number">6</span>, num_leaves=<span class="number">80</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">模型当前最优参数为： &#123;&#x27;min_data_in_leaf&#x27;: 45&#125;</span></span><br><span class="line"><span class="string">模型当前最优得分为： 0.7352238437118113</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="feature-fraction-1"><a href="#feature-fraction-1" class="headerlink" title="feature_fraction"></a>feature_fraction</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lgb_params = &#123;<span class="string">&#x27;feature_fraction&#x27;</span>: [i / <span class="number">10</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>, <span class="number">10</span>, <span class="number">1</span>)]&#125;</span><br><span class="line">get_best_cv_params(param_grid=lgb_params, max_depth=<span class="number">6</span>, num_leaves=<span class="number">80</span>, min_data_in_leaf=<span class="number">45</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">模型当前最优参数为： &#123;&#x27;feature_fraction&#x27;: 0.5&#125;</span></span><br><span class="line"><span class="string">模型当前最优得分为： 0.7357516064800039</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="reg-lambda-和-reg-alpha"><a href="#reg-lambda-和-reg-alpha" class="headerlink" title="reg_lambda 和 reg_alpha"></a>reg_lambda 和 reg_alpha</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lgb_params = &#123;<span class="string">&#x27;reg_alpha&#x27;</span>: [<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>, <span class="number">0.6</span>], <span class="string">&#x27;reg_lambda&#x27;</span>: [<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>, <span class="number">0.6</span>]&#125;</span><br><span class="line">get_best_cv_params(param_grid=lgb_params, max_depth=<span class="number">6</span>, num_leaves=<span class="number">80</span>, min_data_in_leaf=<span class="number">45</span>, feature_fraction=<span class="number">0.5</span>, )</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">模型当前最优参数为： &#123;&#x27;reg_alpha&#x27;: 0.5, &#x27;reg_lambda&#x27;: 0.4&#125;</span></span><br><span class="line"><span class="string">模型当前最优得分为： 0.7358840540809432</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>总之，看似每一个参数的选择非常简短快速，实际调参过程非常漫长，建议增大步长缩小范围以后再精细调参。</p>
<h1 id="贝叶斯调参"><a href="#贝叶斯调参" class="headerlink" title="贝叶斯调参"></a>贝叶斯调参</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">贝叶斯优化是一种用模型找到函数最小值方法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">贝叶斯方法与随机或网格搜索的不同之处在于:它在尝试下一组超参数时,会参考之前的评估结果,因此可以省去很多无用功</span></span><br><span class="line"><span class="string">贝叶斯调参法使用不断更新的概率模型,通过推断过去的结果来&#x27;集中&#x27;有希望的超参数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">贝叶斯优化问题的四个部分</span></span><br><span class="line"><span class="string">            1.目标函数 - 机器学习模型使用该组超参数在验证集上的损失</span></span><br><span class="line"><span class="string">                        它的输入为一组超参数,输出需要最小化的值(交叉验证损失)</span></span><br><span class="line"><span class="string">            2.域空间 - 要搜索的超参数的取值范围</span></span><br><span class="line"><span class="string">                        在搜索的每次迭代中,贝叶斯优化算法将从域空间为每个超参数选择一个值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">                        当我们进行随机或网格搜索时,域空间是一个网格</span></span><br><span class="line"><span class="string">                        而在贝叶斯优化中,不是按照顺序()网格)或者随机选择一个超参数,而是按照每个超参数的概率分布选择</span></span><br><span class="line"><span class="string">            3.优化算法 - 构造替代函数并选择下一个超参数值进行评估的方法</span></span><br><span class="line"><span class="string">            4.来自目标函数评估的存储结果,包括超参数和验证集上的损失</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>定义目标函数，我们要这个目标函数输出的值最大</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">rf_cv_lgb</span>(<span class="params">num_leaves, max_depth, bagging_fraction, feature_fraction, bagging_freq, min_data_in_leaf,</span></span><br><span class="line"><span class="params">              min_child_weight, min_split_gain, reg_lambda, reg_alpha</span>):</span><br><span class="line">    val = cross_val_score(</span><br><span class="line">        lgb.LGBMRegressor(</span><br><span class="line">            boosting_type=<span class="string">&#x27;gbdt&#x27;</span>, objective=<span class="string">&#x27;binary&#x27;</span>, metrics=<span class="string">&#x27;auc&#x27;</span>, learning_rate=<span class="number">0.1</span>, n_estimators=<span class="number">5000</span>,</span><br><span class="line">            num_leaves=<span class="built_in">int</span>(num_leaves), max_depth=<span class="built_in">int</span>(max_depth), bagging_fraction=<span class="built_in">round</span>(bagging_fraction, <span class="number">2</span>),</span><br><span class="line">            feature_fraction=<span class="built_in">round</span>(feature_fraction, <span class="number">2</span>), bagging_freq=<span class="built_in">int</span>(bagging_freq),</span><br><span class="line">            min_data_in_leaf=<span class="built_in">int</span>(min_data_in_leaf), min_child_weight=min_child_weight,</span><br><span class="line">            min_split_gain=min_split_gain, reg_lambda=reg_lambda, reg_alpha=reg_alpha, n_jobs=-<span class="number">1</span></span><br><span class="line">        ), x_train, y_train, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;roc_auc&#x27;</span></span><br><span class="line">    ).mean()</span><br><span class="line">    <span class="keyword">return</span> val</span><br></pre></td></tr></table></figure>
<p>定义优化参数（域空间）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">rf_bo = BayesianOptimization(</span><br><span class="line">    rf_cv_lgb,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;num_leaves&#x27;</span>: (<span class="number">10</span>, <span class="number">200</span>),</span><br><span class="line">        <span class="string">&#x27;max_depth&#x27;</span>: (<span class="number">3</span>, <span class="number">20</span>),</span><br><span class="line">        <span class="string">&#x27;bagging_fraction&#x27;</span>: (<span class="number">0.5</span>, <span class="number">1.0</span>),</span><br><span class="line">        <span class="string">&#x27;feature_fraction&#x27;</span>: (<span class="number">0.5</span>, <span class="number">1.0</span>),</span><br><span class="line">        <span class="string">&#x27;bagging_freq&#x27;</span>: (<span class="number">0</span>, <span class="number">100</span>),</span><br><span class="line">        <span class="string">&#x27;min_data_in_leaf&#x27;</span>: (<span class="number">10</span>, <span class="number">100</span>),</span><br><span class="line">        <span class="string">&#x27;min_child_weight&#x27;</span>: (<span class="number">0</span>, <span class="number">10</span>),</span><br><span class="line">        <span class="string">&#x27;min_split_gain&#x27;</span>: (<span class="number">0.0</span>, <span class="number">1.0</span>),</span><br><span class="line">        <span class="string">&#x27;reg_alpha&#x27;</span>: (<span class="number">0.0</span>, <span class="number">10</span>),</span><br><span class="line">        <span class="string">&#x27;reg_lambda&#x27;</span>: (<span class="number">0.0</span>, <span class="number">10</span>)</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>开始优化，这里我会有15次迭代后的得分，我取了最高的一次贴上来</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">rf_bo.maximize(n_iter=<span class="number">10</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">|   iter    |  target   | baggin... | baggin... | featur... | max_depth | min_ch... | min_da... | min_sp... | num_le...</span></span><br><span class="line"><span class="string"> | reg_alpha | reg_la... |</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">|  14       |  0.7367   |  0.8748   |  21</span></span><br><span class="line"><span class="string">.07    |  0.9624   |  4.754    |  0.3129   |  21.14    |  0.4187   |  178.2   </span></span><br><span class="line"><span class="string"> |  9.991    |  9.528    |</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>根据优化后的参数建立新的模型，降低学习率并寻找最优模型迭代次数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;调整一个较小的学习率，并通过cv函数确定当前最优的迭代次数&#x27;&#x27;&#x27;</span></span><br><span class="line">base_params_lgb = &#123;</span><br><span class="line">    <span class="string">&#x27;boosting_type&#x27;</span>: <span class="string">&#x27;gbdt&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;metric&#x27;</span>: <span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.01</span>,</span><br><span class="line">    <span class="string">&#x27;num_leaves&#x27;</span>: <span class="number">178</span>,</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: <span class="number">5</span>,</span><br><span class="line">    <span class="string">&#x27;min_data_in_leaf&#x27;</span>: <span class="number">21</span>,</span><br><span class="line">    <span class="string">&#x27;min_child_weight&#x27;</span>: <span class="number">0.31</span>,</span><br><span class="line">    <span class="string">&#x27;bagging_fraction&#x27;</span>: <span class="number">0.88</span>,</span><br><span class="line">    <span class="string">&#x27;feature_fraction&#x27;</span>: <span class="number">0.96</span>,</span><br><span class="line">    <span class="string">&#x27;bagging_freq&#x27;</span>: <span class="number">21</span>,</span><br><span class="line">    <span class="string">&#x27;reg_lambda&#x27;</span>: <span class="number">9.5</span>,</span><br><span class="line">    <span class="string">&#x27;reg_alpha&#x27;</span>: <span class="number">10</span>,</span><br><span class="line">    <span class="string">&#x27;min_split_gain&#x27;</span>: <span class="number">0.42</span>,</span><br><span class="line">    <span class="string">&#x27;nthread&#x27;</span>: <span class="number">8</span>,</span><br><span class="line">    <span class="string">&#x27;seed&#x27;</span>: <span class="number">2020</span>,</span><br><span class="line">    <span class="string">&#x27;silent&#x27;</span>: <span class="literal">True</span>,</span><br><span class="line">    <span class="string">&#x27;verbose&#x27;</span>: -<span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">train_matrix = lgb.Dataset(x_train, label=y_train)</span><br><span class="line">cv_result_lgb = lgb.cv(</span><br><span class="line">    train_set=train_matrix,</span><br><span class="line">    early_stopping_rounds=<span class="number">1000</span>,</span><br><span class="line">    num_boost_round=<span class="number">20000</span>,</span><br><span class="line">    nfold=<span class="number">5</span>,</span><br><span class="line">    stratified=<span class="literal">True</span>,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">    params=base_params_lgb,</span><br><span class="line">    metrics=<span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line">    seed=<span class="number">2020</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;迭代次数 &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(cv_result_lgb[<span class="string">&#x27;auc-mean&#x27;</span>])))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;最终模型的AUC为 &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">max</span>(cv_result_lgb[<span class="string">&#x27;auc-mean&#x27;</span>])))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">迭代次数 9364</span></span><br><span class="line"><span class="string">最终模型的AUC为 0.7378500759884923</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>模型参数已经确定，建立最终模型并对验证集进行验证</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">cv_scores = []</span><br><span class="line"><span class="keyword">for</span> i, (train_index, valid_index) <span class="keyword">in</span> <span class="built_in">enumerate</span>(kf.split(x_train, y_train)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;*** &#123;&#125; ***&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(i+<span class="number">1</span>)))</span><br><span class="line">    x_train_split, y_train_split, x_valid, y_valid = x_train.iloc[train_index], y_train[train_index], \</span><br><span class="line">                                                     x_train.iloc[valid_index], y_train[valid_index]</span><br><span class="line">    train_matrix = lgb.Dataset(x_train_split, label=y_train_split)</span><br><span class="line">    valid_matrix = lgb.Dataset(x_valid, label=y_valid)</span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;boosting_type&#x27;</span>: <span class="string">&#x27;gbdt&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;metric&#x27;</span>: <span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.01</span>,</span><br><span class="line">        <span class="string">&#x27;num_leaves&#x27;</span>: <span class="number">178</span>,</span><br><span class="line">        <span class="string">&#x27;max_depth&#x27;</span>: <span class="number">5</span>,</span><br><span class="line">        <span class="string">&#x27;min_data_in_leaf&#x27;</span>: <span class="number">21</span>,</span><br><span class="line">        <span class="string">&#x27;min_child_weight&#x27;</span>: <span class="number">0.31</span>,</span><br><span class="line">        <span class="string">&#x27;bagging_fraction&#x27;</span>: <span class="number">0.88</span>,</span><br><span class="line">        <span class="string">&#x27;feature_fraction&#x27;</span>: <span class="number">0.96</span>,</span><br><span class="line">        <span class="string">&#x27;bagging_freq&#x27;</span>: <span class="number">21</span>,</span><br><span class="line">        <span class="string">&#x27;reg_lambda&#x27;</span>: <span class="number">9.5</span>,</span><br><span class="line">        <span class="string">&#x27;reg_alpha&#x27;</span>: <span class="number">10</span>,</span><br><span class="line">        <span class="string">&#x27;min_split_gain&#x27;</span>: <span class="number">0.42</span>,</span><br><span class="line">        <span class="string">&#x27;nthread&#x27;</span>: <span class="number">8</span>,</span><br><span class="line">        <span class="string">&#x27;seed&#x27;</span>: <span class="number">2020</span>,</span><br><span class="line">        <span class="string">&#x27;silent&#x27;</span>: <span class="literal">True</span>,</span><br><span class="line">        <span class="string">&#x27;verbose&#x27;</span>: -<span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">    model = lgb.train(params, train_set=train_matrix, num_boost_round=<span class="number">9364</span>, valid_sets=valid_matrix,</span><br><span class="line">                      verbose_eval=<span class="number">1000</span>, early_stopping_rounds=<span class="number">200</span>)</span><br><span class="line">    val_pred = model.predict(x_valid, num_iteration=model.best_iteration)</span><br><span class="line">    cv_scores.append(roc_auc_score(y_valid, val_pred))</span><br><span class="line">    <span class="built_in">print</span>(cv_scores)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;lgb_scotrainre_list: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(cv_scores))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;lgb_score_mean: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(np.mean(cv_scores)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;lgb_score_std: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(np.std(cv_scores)))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">lgb_scotrainre_list: [0.7386297996035015, 0.7356995636689628, 0.73900352698853, 0.7382979036633256, 0.7369681848895435]</span></span><br><span class="line"><span class="string">lgb_score_mean: 0.7377197957627727</span></span><br><span class="line"><span class="string">lgb_score_std: 0.0012211910753377566</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>使用训练集数据进行模型训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">final_model_lgb = lgb.train(base_params_lgb, train_set=train_matrix, valid_sets=valid_matrix, num_boost_round=<span class="number">13000</span>,</span><br><span class="line">                            verbose_eval=<span class="number">1000</span>, early_stopping_rounds=<span class="number">200</span>)</span><br></pre></td></tr></table></figure>
<p>预测，并计算roc的相关指标</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val_pred_lgb = final_model_lgb.predict(x_valid)</span><br><span class="line">fpr, tpr, threshold = metrics.roc_curve(y_valid, val_pred_lgb)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;调参后lgb在验证集上的AUC： &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(roc_auc))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;调参后lgb在验证集上的AUC： 0.7369681848895435&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;Validation ROC&#x27;</span>)</span><br><span class="line">plt.plot(fpr, tpr, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Val AUC = %0.4f&#x27;</span> % roc_auc)</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">plt.xlim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;ROC&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True Positive Rate&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;False Positive Rate&#x27;</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], <span class="string">&#x27;r--&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>我的图片没有保存，总之结果和调参前相差不大</p>
<h2 id="保存模型到本地"><a href="#保存模型到本地" class="headerlink" title="保存模型到本地"></a>保存模型到本地</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pickle.dump(final_model_lgb, <span class="built_in">open</span>(<span class="string">&#x27;model/model_lgb_1.pkl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>))</span><br></pre></td></tr></table></figure>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这次调参下来，发现费了很大的功夫，模型的效果提升微乎其微，所以调参的优先级应该排在特征工程之后。选择什么样的模型，以及选择哪些数据作为特征训练，特征应该进行怎样的处理，这些特征工程对于分数的提高应该更大。<br>下一节在尝试模型融合之前，我会尝试用不同的模型先简单测试，看一下哪些模型适合该场景，另外在训练前，我需要先根据特征的重要性做一个特征的筛选，最后训练2-3个模型后再进行融合。希望分数能有一个大的提高。</p>

    </div>

    
    
    
	
	  <div>
		<div>
    
        <div style="text-align:center;color: #ccc;font-size:24px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
	  </div>
	
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>小书包
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://example.com/2023/04/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83_%E9%87%91%E8%9E%8D%E9%A3%8E%E6%8E%A7_Task4_%E5%BB%BA%E6%A8%A1%E8%B0%83%E5%8F%82/" title="机器学习训练_金融风控_Task4_建模调参">http://example.com/2023/04/24/机器学习训练_金融风控_Task4_建模调参/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/python/" rel="tag"># python</a>
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
              <a href="/tags/%E9%87%91%E8%9E%8D%E9%A3%8E%E6%8E%A7/" rel="tag"># 金融风控</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/04/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83_%E9%87%91%E8%9E%8D%E9%A3%8E%E6%8E%A7_Task3_%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" rel="prev" title="机器学习训练_金融风控_Task3_特征工程">
      <i class="fa fa-chevron-left"></i> 机器学习训练_金融风控_Task3_特征工程
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/04/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83_%E9%87%91%E8%9E%8D%E9%A3%8E%E6%8E%A7_Task5_%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/" rel="next" title="机器学习训练_金融风控_Task5_模型融合">
      机器学习训练_金融风控_Task5_模型融合 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BA%8F"><span class="nav-number">1.</span> <span class="nav-text">序</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87"><span class="nav-number">2.</span> <span class="nav-text">数据准备</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%BC%E5%85%A5%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93"><span class="nav-number">2.1.</span> <span class="nav-text">导入第三方库</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="nav-number">2.2.</span> <span class="nav-text">读取数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8E%8B%E7%BC%A9%E6%95%B0%E6%8D%AE"><span class="nav-number">2.3.</span> <span class="nav-text">压缩数据</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AE%80%E5%8D%95%E5%BB%BA%E6%A8%A1"><span class="nav-number">3.</span> <span class="nav-text">简单建模</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BB%BA%E6%A8%A1%E4%B9%8B%E5%89%8D%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="nav-number">3.1.</span> <span class="nav-text">建模之前的数据处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E2%80%98employmentLength%E2%80%99-%E8%BD%AC%E6%8D%A2%E4%B8%BA%E6%95%B0%E5%80%BC"><span class="nav-number">3.1.1.</span> <span class="nav-text">‘employmentLength’ - 转换为数值</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E2%80%98earliesCreditLine%E2%80%99-%E5%88%86%E5%88%AB%E6%8F%90%E5%8F%96%E5%B9%B4%E4%BB%BD%E5%92%8C%E6%9C%88%E4%BB%BD%E5%81%9A%E6%8B%BC%E6%8E%A5"><span class="nav-number">3.1.2.</span> <span class="nav-text">‘earliesCreditLine’ - 分别提取年份和月份做拼接</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E2%80%98issueDate%E2%80%99-%E4%BB%8E%E6%95%B0%E6%8D%AE%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%87%BA%EF%BC%8CissueDate%E4%BB%8E2017%E5%B9%B46%E6%9C%881%E6%97%A5%E5%BC%80%E5%A7%8B%EF%BC%9B%E6%95%B0%E6%8D%AE%E6%8C%89%E7%85%A7%E6%AD%A4%E8%8A%82%E7%82%B9%E7%BB%9F%E8%AE%A1%E5%A4%A9%E6%95%B0"><span class="nav-number">3.1.3.</span> <span class="nav-text">‘issueDate’ - 从数据可以看出，issueDate从2017年6月1日开始；数据按照此节点统计天数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#one-hot%E7%BC%96%E7%A0%81"><span class="nav-number">3.2.</span> <span class="nav-text">one-hot编码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%87%86%E5%A4%87%E8%AE%AD%E7%BB%83%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86"><span class="nav-number">3.3.</span> <span class="nav-text">准备训练集和测试集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%94%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E5%87%86%E5%A4%87"><span class="nav-number">3.4.</span> <span class="nav-text">五折交叉验证准备</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BB%BA%E6%A8%A1-Lightgbm"><span class="nav-number">4.</span> <span class="nav-text">建模 - Lightgbm</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B0%86%E8%AE%AD%E7%BB%83%E9%9B%86%E5%88%86%E4%B8%BA5%E4%BB%BD%EF%BC%8C4%E4%BB%BD%E4%BD%9C%E4%B8%BA%E8%AE%AD%E7%BB%83%E9%9B%86%EF%BC%8C1%E4%BB%BD%E4%BD%9C%E4%B8%BA%E9%AA%8C%E8%AF%81%E9%9B%86"><span class="nav-number">4.1.</span> <span class="nav-text">将训练集分为5份，4份作为训练集，1份作为验证集</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%B0%83%E5%8F%82"><span class="nav-number">5.</span> <span class="nav-text">调参</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B4%AA%E5%BF%83%E8%B0%83%E5%8F%82"><span class="nav-number">5.1.</span> <span class="nav-text">贪心调参</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#objective"><span class="nav-number">5.1.1.</span> <span class="nav-text">objective</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#max-depth"><span class="nav-number">5.1.2.</span> <span class="nav-text">max_depth</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#num-leaves-%E4%B8%BA%E4%BA%86%E9%98%B2%E6%AD%A2%E8%BF%87%E6%8B%9F%E5%90%88%EF%BC%8Cnum-leaves%E8%A6%81%E5%B0%8F%E4%BA%8E2-max-depth-2-10-x3D-1024"><span class="nav-number">5.1.3.</span> <span class="nav-text">num_leaves - 为了防止过拟合，num_leaves要小于2^max_depth(2^10&#x3D;1024)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#min-data-in-leaf"><span class="nav-number">5.1.4.</span> <span class="nav-text">min_data_in_leaf</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#min-child-weight"><span class="nav-number">5.1.5.</span> <span class="nav-text">min_child_weight</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#bagging-fraction-bagging-freq"><span class="nav-number">5.1.6.</span> <span class="nav-text">bagging_fraction + bagging_freq</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#feature-fraction"><span class="nav-number">5.1.7.</span> <span class="nav-text">feature_fraction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#reg-lambda"><span class="nav-number">5.1.8.</span> <span class="nav-text">reg_lambda</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#reg-alpha"><span class="nav-number">5.1.9.</span> <span class="nav-text">reg_alpha</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#learning-rate"><span class="nav-number">5.1.10.</span> <span class="nav-text">learning_rate</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BD%91%E6%A0%BC%E8%B0%83%E5%8F%82"><span class="nav-number">5.2.</span> <span class="nav-text">网格调参</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%88%E8%B0%83-max-depth%E5%92%8C-num-leaves"><span class="nav-number">5.2.1.</span> <span class="nav-text">先调 max_depth和 num_leaves</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#min-data-in-leaf%E5%92%8Cmin-child-weight"><span class="nav-number">5.2.2.</span> <span class="nav-text">min_data_in_leaf和min_child_weight</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#feature-fraction-1"><span class="nav-number">5.2.3.</span> <span class="nav-text">feature_fraction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#reg-lambda-%E5%92%8C-reg-alpha"><span class="nav-number">5.2.4.</span> <span class="nav-text">reg_lambda 和 reg_alpha</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E8%B0%83%E5%8F%82"><span class="nav-number">6.</span> <span class="nav-text">贝叶斯调参</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BF%9D%E5%AD%98%E6%A8%A1%E5%9E%8B%E5%88%B0%E6%9C%AC%E5%9C%B0"><span class="nav-number">6.1.</span> <span class="nav-text">保存模型到本地</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">7.</span> <span class="nav-text">总结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">小书包</p>
  <div class="site-description" itemprop="description">种一棵树最好的时间是十年前，其次是现在</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">12</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/FelixBigTree" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;FelixBigTree" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/598376210@qq.com" title="E-Mail → 598376210@qq.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2023-04 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">小书包</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">198k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">3:01</span>
</div>
  <!--div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>


    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>
<!-- 不蒜子计数初始值纠正 -->
<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});
</script> 

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":"wanko","bottom":-30,"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
